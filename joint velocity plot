from google.colab import drive
drive.mount('/content/drive')

# List of joint names in the NTU RGB+D dataset
joint_names = [
    "SpineBase", "SpineMid", "Neck", "Head", "ShoulderLeft", "ElbowLeft", "WristLeft", "HandLeft", "ShoulderRight",
    "ElbowRight", "WristRight", "HandRight", "HipLeft", "KneeLeft", "AnkleLeft", "FootLeft", "HipRight", "KneeRight",
    "AnkleRight", "FootRight", "SpineShoulder", "HandTipLeft", "ThumbLeft", "HandTipRight", "ThumbRight"
]

# List of action names in the NTU RGB+D dataset
action_names = [
    "Drink water", "Eat meal/snack", "Brush teeth", "Brush hair", "Drop", "Pickup", "Throw",
    "Sit down", "Stand up (from sitting position)", "Clapping", "Reading", "Writing",
    "Tear up paper", "Wear jacket", "Take off jacket", "Wear a shoe", "Take off a shoe",
    "Wear on glasses", "Take off glasses", "Put on a hat/cap", "Take off a hat/cap", "Cheer up",
    "Hand waving", "Kicking something", "Reach into pocket", "Hopping (one foot jumping)", "Jump up",
    "Make a phone call/answer phone", "Playing with phone/tablet", "Typing on a keyboard",
    "Pointing to something with finger", "Taking a selfie", "Check time (from watch)",
    "Rub two hands together", "Nod head/bow", "Shake head", "Wipe face", "Salute",
    "Put the palms together", "Cross hands in front (say stop)", "Sneeze/cough", "Staggering",
    "Falling", "Touch head (headache)", "Touch chest (stomachache/heart pain)",
    "Touch back (backache)", "Touch neck (neckache)", "Nausea or vomiting condition",
    "Use a fan (with hand or paper)/feeling warm", "Punching/slapping other person",
    "Kicking other person", "Pushing other person", "Pat on back of other person",
    "Point finger at the other person", "Hugging other person", "Giving something to other person",
    "Touch other personâ€™s pocket", "Handshaking", "Walking towards each other",
    "Walking apart from each other"
]

import matplotlib.pyplot as plt
import os
import glob
import numpy as np
import tensorflow as tf
from tensorflow.keras.layers import Input, Bidirectional, GRU, Dense, Reshape, Flatten, GlobalAveragePooling1D, MultiHeadAttention, LayerNormalization
from tensorflow.keras.models import Model
from sklearn.model_selection import train_test_split

import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
from torch.utils.data import DataLoader, TensorDataset, random_split

# Set device
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Define the path to the NTU RGB+D dataset
dataset_path = '/content/drive/MyDrive/ntu-rgbd'

# Function to load skeleton data and labels
def load_skeleton_data_and_labels(dataset_path, max_frames=300):
    all_skeletons = []
    all_labels = []

    for file in glob.glob(os.path.join(dataset_path, '*.skeleton')):
        with open(file, 'r') as f:
            data = f.readlines()

        num_frames = int(data[0].strip())
        skeletons = []
        index = 1
        for _ in range(num_frames):
            num_bodies = int(data[index].strip())
            index += 1
            for _ in range(num_bodies):
                index += 2
                joints = []
                for _ in range(25):  # NTU dataset has 25 joints
                    joint_data = list(map(float, data[index].strip().split()))
                    joints.append(joint_data[:3])  # Use only (x, y, z) coordinates
                    index += 1
                skeletons.append(joints)

        skeletons = np.array(skeletons)  # shape: (num_frames, 25, 3)

        if skeletons.shape[0] < max_frames:
            padding = np.zeros((max_frames - skeletons.shape[0], 25, 3))
            skeletons = np.vstack((skeletons, padding))
        else:
            skeletons = skeletons[:max_frames]

        action_id = int(file.split('A')[1][:3]) - 1  # Adjust to 0-based index
        all_skeletons.append(skeletons)
        all_labels.append(action_id)

    return np.array(all_skeletons), np.array(all_labels)

# Function to calculate velocity
def calculate_velocity(skeletons):
    velocity = np.diff(skeletons, axis=0)
    speed = np.linalg.norm(velocity, axis=-1)
    return speed

# Function to build attention model
def build_attention_model(input_shape, num_heads, key_dim):
    input_layer = Input(shape=input_shape)
    attention_output = MultiHeadAttention(num_heads=num_heads, key_dim=key_dim)(input_layer, input_layer)
    attention_output = LayerNormalization(epsilon=1e-6)(attention_output)
    attention_scores = MultiHeadAttention(num_heads=num_heads, key_dim=key_dim)(input_layer, input_layer, return_attention_scores=True)[1]
    return Model(inputs=input_layer, outputs=[attention_output, attention_scores])

# Function to find the center frame using attention weights
def find_center_frame(attention_weights):
    return np.argmax(attention_weights)

# Adaptive Segmentation Using Attention Weights
def adaptive_segmentation_using_attention(skeletons, center_frame, attention_weights, threshold=0.9):
    half_length = 0
    max_length = min(center_frame, len(skeletons) - center_frame)
    # print(center_frame)

    for i in range(1, max_length): # Error cause when i = 148, max_length = min(149, 300 - 149) =149
        # print(attention_weights[center_frame - i][1])
        # print(threshold * attention_weights[center_frame][1])
        if attention_weights[center_frame - i][1] < threshold * attention_weights[center_frame][1] and attention_weights[center_frame + i][1] < threshold *  attention_weights[center_frame][1]:
            break
        half_length += 1

    start = max(0, center_frame - half_length)
    end = min(len(skeletons), center_frame + half_length + 1)
    return skeletons[start:end]

# Function to plot velocity vs time for all joints for each label
def plot_velocity_vs_time_for_all_labels(skeletons, labels, action_names, joint_names):
    unique_labels = np.unique(labels)

    # Lists to store the results
    # center_frames_attention = []
    # significant_segments = []

    for label in unique_labels:
        action_name = action_names[label]
        label_indices = np.where(labels == label)[0]

        # Calculate the velocity and prepare the input for the attention model
        velocity = calculate_velocity(skeletons[label_indices])
        # Reshape velocity to 3D for the attention model
        velocity_input = np.reshape(velocity, (1, velocity.shape[0], -1))  # Shape (1, num_frames, num_joints * 3)

        # Build and compile the attention model
        attention_model = build_attention_model(input_shape=(velocity_input.shape[1], velocity_input.shape[2]), num_heads=8, key_dim=16) # Adjust input shape
        attention_output, attention_scores = attention_model(velocity_input)

        # Calculate attention weights
        attention_weights = np.mean(attention_scores, axis=1).flatten()
        # print(attention_weights.shape) # 576

        # Map attention scores back to original frame indices
        frame_indices = np.arange(num_frames)
        frame_attention_pairs = sorted(zip(frame_indices, attention_weights), key=lambda x: x[1], reverse=True)
        # print(frame_attention_pairs.shape) # list

        # Find the center frame using attention weights
        center_frame = find_center_frame([pair[1] for pair in frame_attention_pairs])
        # center_frames_attention.append(frame_attention_pairs[center_frame][0]) # frame_attention_pairs[center_frame][0] is the true center frame

        # Perform adaptive segmentation using attention weights
        attention_weights_pair = sorted(frame_attention_pairs, key=lambda x: x[0], reverse=False)
        significant_segment = adaptive_segmentation_using_attention(skeletons, frame_attention_pairs[center_frame][0], attention_weights_pair)
        # significant_segments.append(significant_segment)

        print(f"Significant Segment : Start Frame: {frame_attention_pairs[center_frame][0] - len(significant_segment)//2}, Length: {len(significant_segment)}")


        plt.figure(figsize=(15, 10))
        plt.title(f'Velocity vs Time for Action: {action_name}')
        plt.xlabel('Time (frames)')
        plt.ylabel('Velocity')

        joint_velocities = {joint: [] for joint in range(len(joint_names))}

        for idx in label_indices:
            skeleton = skeletons[idx]
            velocity = calculate_velocity(skeleton)
            for joint in range(velocity.shape[1]):
                joint_velocities[joint].append(velocity[:, joint])


        for joint in joint_velocities:
            avg_velocity = np.mean(joint_velocities[joint], axis=0)
            plt.plot(avg_velocity, label=f'{joint_names[joint]}')

        plt.legend(loc='upper right', bbox_to_anchor=(1.1, 1))
        plt.show()



# Load skeleton data and labels
skeletons, labels = load_skeleton_data_and_labels(dataset_path)
print(f'Skeleton data shape: {skeletons.shape}')
print(f'Labels shape: {labels.shape}')
num_frames = 300

# Plot velocity vs time for all joints for each label
plot_velocity_vs_time_for_all_labels(skeletons, labels, action_names, joint_names)
